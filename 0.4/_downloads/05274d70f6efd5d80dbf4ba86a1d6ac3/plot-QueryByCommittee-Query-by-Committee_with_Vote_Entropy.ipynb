{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Query-by-Committee with Vote Entropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt, animation\nfrom sklearn.datasets import make_blobs\n\nfrom skactiveml.utils import MISSING_LABEL, labeled_indices, unlabeled_indices\nfrom skactiveml.visualization import plot_utilities, plot_decision_boundary\n\nfrom skactiveml.classifier import SklearnClassifier, ParzenWindowClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom skactiveml.pool import QueryByCommittee\n\nrandom_state = np.random.RandomState(0)\n\n# Build a dataset.\nX, y_true = make_blobs(n_samples=200, n_features=2,\n                       centers=[[0, 1], [-3, .5], [-1, -1], [2, 1], [1, -.5]],\n                       cluster_std=.7, random_state=random_state)\ny_true = y_true % 2\ny = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\n\n# Initialise the classifier.\nclf = SklearnClassifier(BaggingClassifier(ParzenWindowClassifier()), classes=np.unique(y_true))\n# Initialise the query strategy.\nqs = QueryByCommittee(method='vote_entropy')\n\n\n# Preparation for plotting.\nfig, ax = plt.subplots()\nfeature_bound = [[min(X[:, 0]), min(X[:, 1])], [max(X[:, 0]), max(X[:, 1])]]\nartists = []\n\n# The active learning cycle:\nn_cycles = 20\nfor c in range(n_cycles):\n    # Fit the classifier.\n    clf.fit(X, y)\n\n    # Get labeled instances.\n    X_labeled = X[labeled_indices(y)]\n\n    # Query the next instance/s.\n    query_idx = qs.query(X=X, y=y, ensemble=clf)\n\n    # Plot the labeled data.\n    coll_old = list(ax.collections)\n    title = ax.text(\n        0.5, 1.05, f\"Decision boundary after acquring {c} labels\",\n        size=plt.rcParams[\"axes.titlesize\"], ha=\"center\",\n        transform=ax.transAxes\n    )\n    ax = plot_utilities(qs, X=X, y=y, ensemble=clf,\n                        candidates=None, res=25,\n                        feature_bound=feature_bound, ax=ax)\n    ax.scatter(X[:, 0], X[:, 1], c=y_true, cmap=\"coolwarm\", marker=\".\",\n               zorder=2)\n    ax.scatter(X_labeled[:, 0], X_labeled[:, 1], c=\"grey\", alpha=.8,\n               marker=\".\", s=300)\n    ax = plot_decision_boundary(clf, feature_bound, ax=ax)\n\n    coll_new = list(ax.collections)\n    coll_new.append(title)\n    artists.append([x for x in coll_new if (x not in coll_old)])\n\n    # Label the queried instances.\n    y[query_idx] = y_true[query_idx]\n\nani = animation.ArtistAnimation(fig, artists, interval=1000, blit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../examples/pool_classification_legend.png\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rubric:: References:\n\nThe implementation of this strategy is based on :footcite:t:`seung1992query` and :footcite:t:`engelson1996minimizing`.\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}