{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Expected Model Variance Reduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The generated animation can be found at the bottom of the page.</p></div>\n\n| **Google Colab Note**: If the notebook fails to run after installing the\n  needed packages, try to restart the runtime (Ctrl + M) under\n  Runtime -> Restart session.\n\n<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" target=\"https://colab.research.google.com/github/scikit-activeml/scikit-activeml-docs/blob/gh-pages/latest/generated/sphinx_gallery_notebooks//pool/plot-ExpectedModelVarianceReduction-Expected_Model_Variance_Reduction.ipynb\">\n\n| **Notebook Dependencies**\n| Uncomment the following cell to install all dependencies for this\n  tutorial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install scikit-activeml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n  <hr style=\"border-style: solid; border-top: 1px solid; border-right: 0; border-bottom: 0; border-left: 0;\">\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt, animation\nfrom scipy.stats import uniform\n\nfrom skactiveml.utils import MISSING_LABEL, labeled_indices, is_labeled\n\nfrom skactiveml.regressor import NICKernelRegressor\nfrom skactiveml.pool import ExpectedModelVarianceReduction\n\n# Set a fixed random state for reproducibility.\nrandom_state = np.random.RandomState(0)\n\n\ndef true_function(X_):\n    \"\"\"Compute the true underlying function.\"\"\"\n    return (X_**3 + 2 * X_**2 + X_ - 1).flatten()\n\n\n# Generate samples.\nn_samples = 100\nX = np.concatenate(\n    [\n        uniform.rvs(0, 1.5, 9 * n_samples // 10, random_state=random_state),\n        uniform.rvs(1.5, 0.5, n_samples // 10, random_state=random_state),\n    ]\n).reshape(-1, 1)\n\n# Define noise: higher noise for X < 1 and lower otherwise.\nnoise = np.vectorize(\n    lambda x: random_state.rand() * 1.5 if x < 1 else random_state.rand() * 0.5\n)\n\n# Build the dataset.\ny_true = true_function(X) + noise(X).flatten()\ny = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\nX_test = np.linspace(0, 2, num=100).reshape(-1, 1)\n\n# Initialise the regressor.\nreg = NICKernelRegressor(random_state=random_state, metric_dict={'gamma': 15.0})\n\n# Initialise the query strategy.\nqs = ExpectedModelVarianceReduction()\n\n# Prepare the plotting area.\nfig, (ax_1, ax_2) = plt.subplots(2, 1, sharex=True)\nartists = []\n\n# Active learning cycle.\nn_cycles = 20\nfor c in range(n_cycles):\n    # Fit the regressor using the current labels.\n    reg.fit(X, y)\n\n    # Query the next sample(s).\n    query_idx = qs.query(X=X, y=y, reg=reg)\n\n    # Record current plot elements.\n    coll_old = list(ax_1.collections) + list(ax_2.collections)\n    title = ax_1.text(\n        0.5, 1.05,\n        f\"Prediction after acquiring {c} labels\",\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=ax_1.transAxes,\n    )\n\n    # Compute utility values for the test candidates.\n    _, utilities_test = qs.query(X=X, y=y, reg=reg, candidates=X_test, return_utilities=True)\n    utilities_test = (utilities_test - utilities_test.min()).flatten()\n    if np.any(utilities_test != utilities_test[0]):\n        utilities_test /= utilities_test.max()\n\n    # Plot utility information on the second axis.\n    (utility_line,) = ax_2.plot(X_test, utilities_test, c=\"green\")\n    utility_fill = plt.fill_between(X_test.flatten(), utilities_test, color=\"green\", alpha=0.3)\n\n    # Plot the samples and their labels.\n    is_lbld = is_labeled(y)\n    ax_1.scatter(X[~is_lbld], y_true[~is_lbld], c=\"lightblue\")\n    ax_1.scatter(X[is_lbld], y[is_lbld], c=\"orange\")\n\n    # Predict and plot the regressor's output.\n    y_pred = reg.predict(X_test)\n    (prediction_line,) = ax_1.plot(X_test, y_pred, c=\"black\")\n\n    # Capture new plot elements.\n    coll_new = list(ax_1.collections) + list(ax_2.collections)\n    coll_new.append(title)\n    artists.append(\n        [x for x in coll_new if (x not in coll_old)]\n        + [utility_line, utility_fill, prediction_line]\n    )\n\n    # Update labels for the queried sample.\n    y[query_idx] = y_true[query_idx]\n\n# Create an animation from the collected frames.\nani = animation.ArtistAnimation(fig, artists, interval=1000, blit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../examples/pool_regression_legend.png\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rubric:: References:\n\nThe implementation of this strategy is based on :footcite:t:`cohn1996active`.\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}