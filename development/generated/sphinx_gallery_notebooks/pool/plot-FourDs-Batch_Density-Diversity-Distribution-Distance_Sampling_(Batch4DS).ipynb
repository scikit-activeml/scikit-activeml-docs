{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Batch Density-Diversity-Distribution-Distance Sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The generated animation can be found at the bottom of the page.</p></div>\n\n| **Google Colab Note**: If the notebook fails to run after installing the\n  needed packages, try to restart the runtime (Ctrl + M) under\n  Runtime -> Restart session.\n\n<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" target=\"https://colab.research.google.com/github/scikit-activeml/scikit-activeml-docs/blob/gh-pages/latest/generated/sphinx_gallery_notebooks//pool/plot-FourDs-Batch_Density-Diversity-Distribution-Distance_Sampling_(Batch4DS).ipynb\">\n\n| **Notebook Dependencies**\n| Uncomment the following cell to install all dependencies for this\n  tutorial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install scikit-activeml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n  <hr style=\"border-style: solid; border-top: 1px solid; border-right: 0; border-bottom: 0; border-left: 0;\">\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt, animation\nfrom sklearn.datasets import make_blobs\n\nfrom skactiveml.utils import MISSING_LABEL, labeled_indices, unlabeled_indices\nfrom skactiveml.visualization import (\n    plot_utilities,\n    plot_decision_boundary,\n    plot_contour_for_samples,\n)\n\nfrom skactiveml.classifier import MixtureModelClassifier\nfrom skactiveml.pool import FourDs\nfrom sklearn.mixture import GaussianMixture\n\n# Set a fixed random state for reproducibility.\nrandom_state = np.random.RandomState(0)\n\n# Build a dataset.\nX, y_true = make_blobs(\n    n_samples=200,\n    n_features=2,\n    centers=[[0, 1], [-3, 0.5], [-1, -1], [2, 1], [1, -0.5]],\n    cluster_std=0.7,\n    random_state=random_state,\n)\ny_true = y_true % 2\ny = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\n\n# Initialise the classifier.\nclf = MixtureModelClassifier(classes=[0, 1], mixture_model=GaussianMixture(n_components=5))\n# Initialise the query strategy.\nqs = FourDs()\n\n# Preparation for plotting: create a 2x2 grid of subplots.\nfig, axs = plt.subplots(2, 2, constrained_layout=True)\nfeature_bound = [[min(X[:, 0]), min(X[:, 1])], [max(X[:, 0]), max(X[:, 1])]]\nartists = [[] for j in range(5)]\n\n# Active learning cycle.\nn_cycles = 5\nfor c in range(n_cycles):\n    # Train the classifier with the current labels.\n    clf.fit(X, y)\n\n    # Query the next batch of samples; retrieve both indices and utility values.\n    query_idx, utilities = qs.query(X=X, y=y, clf=clf, batch_size=4, return_utilities=True)\n\n    # Plot results on each subplot.\n    for i, ax in enumerate(axs.flatten()):\n        # Save current collections to identify new plot elements.\n        coll_old = list(ax.collections)\n\n        # Plot the utility contour for the current subplot.\n        plot_contour_for_samples(\n            X,\n            utilities[i],\n            res=25,\n            feature_bound=feature_bound,\n            replace_nan=None,\n            ax=ax,\n        )\n        # Scatter all samples with true labels.\n        ax.scatter(X[:, 0], X[:, 1], c=y_true, cmap=\"coolwarm\", marker=\".\", zorder=2)\n        # Highlight the labeled samples.\n        X_labeled = X[labeled_indices(y)]\n        ax.scatter(\n            X_labeled[:, 0],\n            X_labeled[:, 1],\n            c=\"grey\",\n            alpha=0.8,\n            marker=\".\",\n            s=300,\n        )\n        # Overlay the decision boundary.\n        ax = plot_decision_boundary(clf, feature_bound, ax=ax)\n        # Set the title indicating the current batch and subplot index.\n        ax.set_title(f\"Batch {c+1}, Utilities[{i}]\")\n\n        # Collect new artists (plot elements) added during this cycle.\n        for x in ax.collections:\n            if x not in coll_old:\n                artists[c].append(x)\n\n    # Update the labels for the queried samples.\n    y[query_idx] = y_true[query_idx]\n\n# Create the animation using the collected artists.\nani = animation.ArtistAnimation(fig, artists, interval=1000, blit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../examples/pool_classification_legend.png\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rubric:: References:\n\nThe implementation of this strategy is based on :footcite:t:`reitmaier2013let`.\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}