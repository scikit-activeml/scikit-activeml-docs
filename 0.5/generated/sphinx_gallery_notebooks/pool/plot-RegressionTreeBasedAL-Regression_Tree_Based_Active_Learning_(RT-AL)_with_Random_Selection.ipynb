{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Regression Tree Based Active Learning (RT-AL) with Random Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The generated animation can be found at the bottom of the page.</p></div>\n\n| **Google Colab Note**: If the notebook fails to run after installing the\n  needed packages, try to restart the runtime (Ctrl + M) under\n  Runtime -> Restart session.\n\n<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" target=\"https://colab.research.google.com/github/scikit-activeml/scikit-activeml-docs/blob/gh-pages/latest/generated/sphinx_gallery_notebooks//pool/plot-RegressionTreeBasedAL-Regression_Tree_Based_Active_Learning_(RT-AL)_with_Random_Selection.ipynb\">\n\n| **Notebook Dependencies**\n| Uncomment the following cell to install all dependencies for this\n  tutorial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install scikit-activeml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. raw:: html\n\n   <hr style=\"border-style: solid; border-top: 1px solid; border-right: 0; border-bottom: 0; border-left: 0;\">\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt, animation\nfrom scipy.stats import uniform\n\nfrom skactiveml.utils import MISSING_LABEL, labeled_indices, is_labeled\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom skactiveml.regressor import SklearnRegressor\nfrom skactiveml.pool import RegressionTreeBasedAL\n\nrandom_state = np.random.RandomState(0)\n\n\ndef true_function(X_):\n    return (X_**3 + 2 * X_**2 + X_ - 1).flatten()\n\nn_samples = 100\nX = np.concatenate(\n        [uniform.rvs(0, 1.5, 9 * n_samples // 10, random_state=random_state),\n         uniform.rvs(1.5, 0.5, n_samples // 10, random_state=random_state)]\n    ).reshape(-1, 1)\n\nnoise = np.vectorize(lambda x : random_state.rand() * 1.5 if x < 1\n                                else random_state.rand() * 0.5)\n\n# Build a dataset.\ny_true = true_function(X) + noise(X).flatten()\ny = np.full(shape=y_true.shape, fill_value=MISSING_LABEL)\nX_test = np.linspace(0, 2, num=1000).reshape(-1, 1)\n\n# Initialise the classifier.\nreg = SklearnRegressor(DecisionTreeRegressor(min_samples_leaf=2, random_state=random_state), random_state=random_state)\n# Initialise the query strategy.\nqs = RegressionTreeBasedAL(random_state=random_state)\n\n\n# Preparation for plotting.\nfig, (ax_1, ax_2) = plt.subplots(2, 1, sharex=True)\nartists = []\n\n# The active learning cycle:\nn_cycles = 20\nbatch_size = 3\nfor c in range(n_cycles):\n    # Fit the classifier.\n    reg.fit(X, y)\n\n    # Get labeled instances.\n    X_labeled = X[labeled_indices(y)]\n\n    # Query the next instance/s.\n    query_idx, utilities = qs.query(X=X, y=y, reg=reg, return_utilities=True, batch_size=batch_size)\n\n    # Plot the labeled data.\n    coll_old = list(ax_1.collections) + list(ax_2.collections)\n    title = ax_1.text(\n        0.5,\n        1.05,\n        f\"Prediction after acquring {c} labels\",\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=ax_1.transAxes,\n    )\n\n    sort_mask = np.argsort(X.flatten())\n    X_plot = X.flatten()[sort_mask]\n    utilities_plot = utilities[0][sort_mask]/batch_size\n\n    is_lbld = is_labeled(y)\n\n    (utility_line,) = ax_2.plot(X_plot, utilities_plot, c=\"green\")\n    utility_fill = plt.fill_between(\n        X_plot, utilities_plot, color=\"green\", alpha=0.3\n    )\n\n    ax_1.scatter(X[~is_lbld], y_true[~is_lbld], c=\"lightblue\")\n    ax_1.scatter(X[is_lbld], y[is_lbld], c=\"orange\")\n\n    y_pred = reg.predict(X_test)\n    (prediction_line,) = ax_1.plot(X_test, y_pred, c=\"black\")\n\n    coll_new = list(ax_1.collections) + list(ax_2.collections)\n    coll_new.append(title)\n    artists.append(\n        [x for x in coll_new if (x not in coll_old)]\n        + [utility_line, utility_fill, prediction_line]\n    )\n\n    # Label the queried instances.\n    y[query_idx] = y_true[query_idx]\n\nani = animation.ArtistAnimation(fig, artists, interval=1000, blit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"file://../../examples/pool_regression_legend.png\">\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rubric:: References:\n\nThe implementation of this strategy is based on :footcite:t:`jose2023regression`.\n\n.. footbibliography::\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}